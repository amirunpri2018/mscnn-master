layer {
  name: "G"
  type: "Convolution"
  bottom: "input"
  top: "G"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
 
 
 
layer {
  name: "Theta"
  type: "Convolution"
  bottom: "input"
  top: "Theta"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
 
 
layer {
  name: "Phi"
  type: "Convolution"
  bottom: "input"
  top: "Phi"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
 
 
layer {
    name: "reshape_G"
    type: "Reshape"
    bottom: "G"
    top: "output_G"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
      }
    }
}
 
 
layer {
    name: "reshape_Theta"
    type: "Reshape"
    bottom: "Theta"
    top: "output_Theta"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
      }
    }
}
 
 
layer {
    name: "reshape_Phi"
    type: "Reshape"
    bottom: "Phi"
    top: "output_Phi"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
        dim: -1 # infer it from the other dimensions
      }
    }
}
 
layer {
    name: "Transpose_G"
    type: "Transpose"
    bottom: "output_G"
    top: "Transpose_G"
    transpose_param { dim: 0 dim: 2 dim: 1 }
}
 
layer {
    name: "Transpose_Theta"
    type: "Transpose"
    bottom: "output_Theta"
    top: "Transpose_Theta"
    transpose_param {dim: 0 dim: 2 dim: 1 }
}
 
layer {
    name: "MM_Theta_Phi"
    type: "MatrixMultiplication"
	#type: "MATRIXMultiplication"
    bottom: "Transpose_Theta"
	bottom: "output_Phi"
    top: "MM_Theta_Phi"
}
 
layer {
  name: "MM_Theta_Phi_soft"
  type: "Softmax"
  bottom: "MM_Theta_Phi"
  top: "MM_Theta_Phi_soft"
  SoftmaxParameter {
     axis:2
  }
}
 
 
layer {
    name: "MM_o"
    type: "MatrixMultiplication"
	#type: "MATRIXMultiplication"
    bottom: "MM_Theta_Phi_soft"
	bottom: "output_G"
    top: "MM_o"
}
 
 
layer {
    name: "Transpose_MM"
    type: "Transpose"
    bottom: "MM_o"
    top: "Transpose_MM"
    transpose_param {dim: 0 dim: 2 dim: 1 }
}
 
 
 
layer {
    name: "re_MM"
    type: "Reshape"
    bottom: "Transpose_MM"
    top: "re_MM"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 0
		dim: 176 # infer it from the other dimensions
        dim: -1 # infer it from the other dimensions
      }
    }
}
 
 
layer {
  name: "conv_re"
  type: "Convolution"
  bottom: "re_MM"
  top: "conv_re"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}

